import sqlite3
import os
import nltk
from tqdm import tqdm

# --- Config ---
INPUT_FOLDER = '/home/fulian/RAG/data/processed'
DB_PATH = '/home/fulian/RAG/data/request/inference_results_ensemble.db'

def verify_and_fix_consistency():
    print("ğŸ•µï¸Starting Consistency Check (DB vs File System)...")
    
    if not os.path.exists(DB_PATH):
        print("âš ï¸ No database found. Nothing to verify.")
        return

    conn = sqlite3.connect(DB_PATH)
    cursor = conn.cursor()

    # 1. è·å– DB é‡Œæ‰€æœ‰è®°å½•è¿‡çš„æ–‡ä»¶å
    try:
        cursor.execute("SELECT DISTINCT filename FROM inference_logs")
        db_files = {row[0] for row in cursor.fetchall()}
    except sqlite3.OperationalError:
        print("âš ï¸ Database table not ready yet.")
        return

    print(f"ğŸ“‹ Database contains records for {len(db_files)} files.")
    
    issues_found = 0
    fixed_count = 0

    # 2. éå†æ£€æŸ¥æ¯ä¸€ä¸ªåœ¨ DB é‡Œå®£ç§°â€œå·²å®Œæˆâ€çš„æ–‡ä»¶
    for filename in tqdm(db_files, desc="Verifying Integrity"):
        file_path = os.path.join(INPUT_FOLDER, filename)
        
        # å¦‚æœæ–‡ä»¶åœ¨ç¡¬ç›˜ä¸Šä¸è§äº†ï¼Œè·³è¿‡
        if not os.path.exists(file_path):
            continue

        # A. ä» DB é‡Œé‡å»ºè¯¥æ–‡ä»¶â€œåº”è¯¥â€æœ‰çš„æ ·å­ (Source of Truth)
        # æŒ‰ index æ’åºæå–æ‰€æœ‰æ ‡è®°ä¸º KEEP çš„å¥å­
        cursor.execute("""
            SELECT sentence FROM inference_logs 
            WHERE filename = ? AND model_prediction = 'KEEP'
            ORDER BY sentence_index ASC
        """, (filename,))
        
        kept_sentences_db = [row[0] for row in cursor.fetchall()]
        expected_text = " ".join(kept_sentences_db)

        # B. è¯»å–ç¡¬ç›˜ä¸Šæ–‡ä»¶â€œå®é™…â€çš„æ ·å­
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                actual_text = f.read()
        except Exception:
            continue

        # C. æ¯”è¾ƒ (ç®€å•æ¯”è¾ƒé•¿åº¦æˆ–å†…å®¹)
        # æ³¨æ„ï¼šå®Œå…¨å­—ç¬¦ä¸²ç›¸ç­‰æ¯”è¾ƒå¯èƒ½å› ä¸ºç©ºæ ¼å¤„ç†ç•¥æœ‰ä¸åŒè€Œå¤±è´¥ï¼Œ
        # æ‰€ä»¥æˆ‘ä»¬è¿™é‡Œåšä¸€ä¸ªé€»è¾‘åˆ¤æ–­ï¼šå¦‚æœç¡¬ç›˜ä¸Šçš„æ–‡ä»¶åŒ…å«äº† DB é‡Œæ ‡è®°ä¸º REMOVE çš„å†…å®¹ï¼Œè‚¯å®šæœ‰é—®é¢˜ã€‚
        
        # æ›´ç®€å•çš„åˆ¤æ–­ï¼šå¦‚æœç¡¬ç›˜æ–‡ä»¶é•¿åº¦ æ˜æ˜¾å¤§äº DB é¢„æœŸé•¿åº¦ï¼Œè¯´æ˜æ²¡åˆ å¹²å‡€
        # æˆ–è€…ç›´æ¥ï¼šæ—¢ç„¶ DB æ˜¯çœŸç†ï¼Œæˆ‘ä»¬æ— æ¡ä»¶ä¿¡ä»» DB çš„ KEEP ç»“æœï¼Œç›´æ¥é‡å†™ä¸€æ¬¡æ–‡ä»¶å³å¯ã€‚
        # ä¸ºäº†æ•ˆç‡ï¼Œæˆ‘ä»¬åªåœ¨é•¿åº¦å·®å¼‚å¤§æ—¶é‡å†™ï¼Œæˆ–è€…ç›´æ¥å…¨éƒ¨æ£€æŸ¥ä¸€éã€‚
        
        # è¿™é‡Œæˆ‘ä»¬é‡‡ç”¨â€œå­—ç¬¦çº§æ¯”å¯¹â€ç­–ç•¥æ¥å†³å®šæ˜¯å¦éœ€è¦ä¿®å¤
        # è€ƒè™‘åˆ°ç©ºæ ¼å·®å¼‚ï¼Œæˆ‘ä»¬å»æ‰æ‰€æœ‰ç©ºæ ¼æ¯”è¾ƒ
        clean_expected = expected_text.replace(" ", "")
        clean_actual = actual_text.replace(" ", "")

        if clean_expected != clean_actual:
            issues_found += 1
            # D. ä¿®å¤ï¼šç”¨ DB çš„æ•°æ®è¦†ç›–æ–‡ä»¶
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(expected_text)
            fixed_count += 1
            # print(f"ğŸ”§ Fixed incomplete write for: {filename}")

    conn.close()
    print("\n" + "="*30)
    print("âœ… Consistency Check Complete!")
    print(f"âš ï¸  Inconsistent files found: {issues_found}")
    print(f"ğŸ”§ Files repaired (overwritten with DB data): {fixed_count}")
    print("="*30)

if __name__ == "__main__":
    # ç¡®ä¿ NLTK ç”¨äºè¯»å– (è™½ç„¶è¿™é‡Œä¸»è¦é  DB)
    try:
        nltk.data.find('tokenizers/punkt')
    except LookupError:
        nltk.download('punkt')
        
    verify_and_fix_consistency()